{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "Homework_3_point_cloud_mnist_BAR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5cdd858b34fc40fe955a632fbcf43535": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d6e46a801dfa49cf8e7178764f3bcf83",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f45711a4a81c481f94b5db3f6dfa873a",
              "IPY_MODEL_c0408685a1b04d1e96bb3a9cf91fded3"
            ]
          }
        },
        "d6e46a801dfa49cf8e7178764f3bcf83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f45711a4a81c481f94b5db3f6dfa873a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5819c44336274f74ac0b758fd130ee36",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 70,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 70,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6cd18403219f4aa6a3795de471f23673"
          }
        },
        "c0408685a1b04d1e96bb3a9cf91fded3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1999926355704a5790a5c4fef1b105ed",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 70/70 [14:21&lt;00:00, 12.31s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9805561b86f942ab92273dfd172107b1"
          }
        },
        "5819c44336274f74ac0b758fd130ee36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6cd18403219f4aa6a3795de471f23673": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1999926355704a5790a5c4fef1b105ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9805561b86f942ab92273dfd172107b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BarAvni/deep_learning_2020/blob/master/Homework_3_point_cloud_mnist_BAR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RspKK3UfWKtJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "edf49720-d035-4079-cd78-214680439a78"
      },
      "source": [
        "#if youre running on colab, run this line first to properly load the h5 files\n",
        "!pip install tables --upgrade"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tables\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/c3/8fd9e3bb21872f9d69eb93b3014c86479864cca94e625fd03713ccacec80/tables-3.6.1-cp36-cp36m-manylinux1_x86_64.whl (4.3MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numexpr>=2.6.2 in /usr/local/lib/python3.6/dist-packages (from tables) (2.7.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.3 in /usr/local/lib/python3.6/dist-packages (from tables) (1.18.5)\n",
            "Installing collected packages: tables\n",
            "  Found existing installation: tables 3.4.4\n",
            "    Uninstalling tables-3.4.4:\n",
            "      Successfully uninstalled tables-3.4.4\n",
            "Successfully installed tables-3.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Xdqz9h-WKtR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, Sampler\n",
        "import glob\n",
        "from tqdm.notebook import tqdm\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D13ObnMcWKtY",
        "colab_type": "text"
      },
      "source": [
        "# Homework 3\n",
        "## Point Cloud MNIST with DeepSet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZasj1C6WKtZ",
        "colab_type": "text"
      },
      "source": [
        "below you have a custom dataloader for the point-cloud MNIST dataset,\n",
        "\n",
        "the training and validation datasets are linked from the course website"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8Ky7J7oWKtZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, path):\n",
        "        \n",
        "\n",
        "        \n",
        "        self.df = pd.read_hdf(path)\n",
        "        \n",
        "        self.label = torch.LongTensor(self.df.label)\n",
        "        \n",
        "        self.n_points = self.df.n_points\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "       \n",
        "        return len(self.label)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "    \n",
        "        return torch.FloatTensor(self.df.iloc[idx].xy), self.label[idx]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7TciZETWkWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!wget -O training_ds.h5 https://www.dropbox.com/sh/h7wj4owo5vxwzgp/AACdZ5vjsHRv6utQk0_ZtIH4a?dl=0&preview=training_ds.h5\n",
        "# !wget -O valid_ds.h5 https://www.dropbox.com/sh/h7wj4owo5vxwzgp/AACdZ5vjsHRv6utQk0_ZtIH4a?dl=0&preview=valid_ds.h5"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIoZEUHVX7xQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "a50f5d53-6c11-4a8a-f71e-1c0415e20c6e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1AXBzVDYZy9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds = CustomDataset('/content/drive/My Drive/ML course/training_ds.h5')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqgAeTbQWKtl",
        "colab_type": "text"
      },
      "source": [
        "#### the data is exactly like the MNIST dataset, except that instead of a 28x28 image,\n",
        "#### you get a (N x 2) array of points (different number of points for each item in the dataset) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6e_lx3_WKtm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "6e8741c5-3a58-4498-fb65-5f0a433267b8"
      },
      "source": [
        "fig,ax = plt.subplots(figsize=(5,5))\n",
        "\n",
        "xy = ds[445][0]\n",
        "\n",
        "ax.scatter( xy[:,0],xy[:,1] )\n",
        "\n",
        "ax.set_axis_off()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYB7V44tWKts",
        "colab_type": "text"
      },
      "source": [
        "### the dataset object has a n_points variable that tells us how many points in each item"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7U-pY21TZ5dw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9996a10a-cd67-4e96-ba8c-8e235be31b17"
      },
      "source": [
        "ds.n_points[445]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "131"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSPPL_RTWKts",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "7465b4bb-cc8f-438c-a3b2-1f00d99a3792"
      },
      "source": [
        "ds.n_points"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       117\n",
              "1       130\n",
              "2        88\n",
              "3        70\n",
              "4        97\n",
              "       ... \n",
              "9995    120\n",
              "9996    111\n",
              "9997    114\n",
              "9998     81\n",
              "9999     88\n",
              "Name: n_points, Length: 10000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYoJ5swbWKua",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "b27aa967-d53e-411b-918f-7178f5fa063d"
      },
      "source": [
        "plt.hist(ds.n_points,np.linspace(19.5,260.5,242))\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDMsFJlHWKui",
        "colab_type": "text"
      },
      "source": [
        "## One way to deal with this variable size is to use a custom Batch Sampler\n",
        "\n",
        "https://pytorch.org/docs/stable/data.html\n",
        "\n",
        "This object will tell our dataloader which item indices to request for the batches - \n",
        "and we can \"rig\" it to return batches where all the items have the same N, and therefore we can stack them without a custom colate function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UoTkwdZWKuk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomBatchSampler(Sampler):\n",
        "    def __init__(self, points_per_entry, batch_size):\n",
        "        \n",
        "        self.batch_size = batch_size\n",
        "        self.N_per_entry = points_per_entry\n",
        "        self.batches = {}\n",
        "        \n",
        "    def generate_batches(self):\n",
        "        \n",
        "        self.entries_with_N = {}\n",
        "        running_idx = -1\n",
        "\n",
        "        for N in set(self.N_per_entry):\n",
        "            \n",
        "            self.entries_with_N[N] = np.where(self.N_per_entry == N)[0]\n",
        "\n",
        "            how_many = len(self.entries_with_N[N])\n",
        "            n_batches = np.amax([ how_many / self.batch_size, 1])\n",
        "\n",
        "            self.entries_with_N[N] = np.array_split(np.random.permutation(self.entries_with_N[N]),\n",
        "                                                           n_batches)\n",
        "            for batch in self.entries_with_N[N]:\n",
        "                running_idx += 1\n",
        "                self.batches[running_idx] = batch\n",
        "\n",
        "        self.n_batches = running_idx + 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_batches\n",
        "\n",
        "    def __iter__(self):\n",
        "        \n",
        "        self.generate_batches()\n",
        "        \n",
        "        batch_order = np.random.permutation(np.arange(self.n_batches))\n",
        "        for i in batch_order:\n",
        "            yield self.batches[i]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3Lfw2jPWKu5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 50\n",
        "batch_sampler = CustomBatchSampler(ds.n_points, batch_size)\n",
        "data_loader = DataLoader(ds, batch_sampler=batch_sampler)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcmvwU79WKvD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "14c48b5c-1f9b-4778-96e3-26d0ca00167d"
      },
      "source": [
        "for epoch in range(3):\n",
        "    print(epoch)\n",
        "    for x,y in data_loader:\n",
        "        print(x.shape)\n",
        "    break"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "torch.Size([2, 207, 2])\n",
            "torch.Size([57, 108, 2])\n",
            "torch.Size([15, 187, 2])\n",
            "torch.Size([6, 205, 2])\n",
            "torch.Size([13, 39, 2])\n",
            "torch.Size([33, 162, 2])\n",
            "torch.Size([36, 160, 2])\n",
            "torch.Size([54, 124, 2])\n",
            "torch.Size([53, 99, 2])\n",
            "torch.Size([98, 115, 2])\n",
            "torch.Size([1, 249, 2])\n",
            "torch.Size([25, 172, 2])\n",
            "torch.Size([24, 180, 2])\n",
            "torch.Size([29, 49, 2])\n",
            "torch.Size([63, 109, 2])\n",
            "torch.Size([11, 183, 2])\n",
            "torch.Size([96, 103, 2])\n",
            "torch.Size([30, 167, 2])\n",
            "torch.Size([30, 168, 2])\n",
            "torch.Size([53, 111, 2])\n",
            "torch.Size([53, 139, 2])\n",
            "torch.Size([75, 136, 2])\n",
            "torch.Size([82, 83, 2])\n",
            "torch.Size([1, 243, 2])\n",
            "torch.Size([55, 88, 2])\n",
            "torch.Size([4, 202, 2])\n",
            "torch.Size([12, 43, 2])\n",
            "torch.Size([11, 197, 2])\n",
            "torch.Size([18, 188, 2])\n",
            "torch.Size([57, 108, 2])\n",
            "torch.Size([52, 118, 2])\n",
            "torch.Size([84, 76, 2])\n",
            "torch.Size([50, 156, 2])\n",
            "torch.Size([71, 148, 2])\n",
            "torch.Size([7, 220, 2])\n",
            "torch.Size([51, 77, 2])\n",
            "torch.Size([55, 144, 2])\n",
            "torch.Size([40, 59, 2])\n",
            "torch.Size([28, 50, 2])\n",
            "torch.Size([8, 199, 2])\n",
            "torch.Size([4, 204, 2])\n",
            "torch.Size([51, 87, 2])\n",
            "torch.Size([53, 150, 2])\n",
            "torch.Size([1, 280, 2])\n",
            "torch.Size([4, 213, 2])\n",
            "torch.Size([76, 133, 2])\n",
            "torch.Size([54, 94, 2])\n",
            "torch.Size([23, 48, 2])\n",
            "torch.Size([19, 185, 2])\n",
            "torch.Size([60, 138, 2])\n",
            "torch.Size([7, 201, 2])\n",
            "torch.Size([59, 106, 2])\n",
            "torch.Size([63, 68, 2])\n",
            "torch.Size([1, 26, 2])\n",
            "torch.Size([57, 110, 2])\n",
            "torch.Size([58, 95, 2])\n",
            "torch.Size([2, 245, 2])\n",
            "torch.Size([81, 75, 2])\n",
            "torch.Size([62, 146, 2])\n",
            "torch.Size([92, 120, 2])\n",
            "torch.Size([49, 157, 2])\n",
            "torch.Size([52, 123, 2])\n",
            "torch.Size([47, 135, 2])\n",
            "torch.Size([54, 96, 2])\n",
            "torch.Size([53, 94, 2])\n",
            "torch.Size([75, 69, 2])\n",
            "torch.Size([3, 33, 2])\n",
            "torch.Size([49, 149, 2])\n",
            "torch.Size([94, 84, 2])\n",
            "torch.Size([3, 210, 2])\n",
            "torch.Size([39, 166, 2])\n",
            "torch.Size([51, 87, 2])\n",
            "torch.Size([52, 119, 2])\n",
            "torch.Size([59, 141, 2])\n",
            "torch.Size([29, 54, 2])\n",
            "torch.Size([52, 119, 2])\n",
            "torch.Size([56, 113, 2])\n",
            "torch.Size([56, 113, 2])\n",
            "torch.Size([1, 29, 2])\n",
            "torch.Size([5, 214, 2])\n",
            "torch.Size([27, 165, 2])\n",
            "torch.Size([72, 143, 2])\n",
            "torch.Size([35, 57, 2])\n",
            "torch.Size([1, 25, 2])\n",
            "torch.Size([2, 216, 2])\n",
            "torch.Size([58, 95, 2])\n",
            "torch.Size([52, 123, 2])\n",
            "torch.Size([51, 93, 2])\n",
            "torch.Size([4, 218, 2])\n",
            "torch.Size([95, 130, 2])\n",
            "torch.Size([39, 58, 2])\n",
            "torch.Size([33, 55, 2])\n",
            "torch.Size([81, 122, 2])\n",
            "torch.Size([14, 182, 2])\n",
            "torch.Size([8, 41, 2])\n",
            "torch.Size([54, 124, 2])\n",
            "torch.Size([55, 153, 2])\n",
            "torch.Size([46, 63, 2])\n",
            "torch.Size([64, 109, 2])\n",
            "torch.Size([8, 195, 2])\n",
            "torch.Size([55, 88, 2])\n",
            "torch.Size([28, 177, 2])\n",
            "torch.Size([98, 97, 2])\n",
            "torch.Size([50, 117, 2])\n",
            "torch.Size([8, 38, 2])\n",
            "torch.Size([23, 45, 2])\n",
            "torch.Size([6, 193, 2])\n",
            "torch.Size([37, 171, 2])\n",
            "torch.Size([31, 52, 2])\n",
            "torch.Size([52, 78, 2])\n",
            "torch.Size([54, 64, 2])\n",
            "torch.Size([84, 74, 2])\n",
            "torch.Size([58, 100, 2])\n",
            "torch.Size([81, 125, 2])\n",
            "torch.Size([98, 92, 2])\n",
            "torch.Size([16, 44, 2])\n",
            "torch.Size([53, 105, 2])\n",
            "torch.Size([57, 101, 2])\n",
            "torch.Size([5, 36, 2])\n",
            "torch.Size([3, 28, 2])\n",
            "torch.Size([58, 110, 2])\n",
            "torch.Size([3, 233, 2])\n",
            "torch.Size([73, 67, 2])\n",
            "torch.Size([23, 176, 2])\n",
            "torch.Size([55, 90, 2])\n",
            "torch.Size([5, 203, 2])\n",
            "torch.Size([3, 221, 2])\n",
            "torch.Size([2, 211, 2])\n",
            "torch.Size([51, 121, 2])\n",
            "torch.Size([16, 40, 2])\n",
            "torch.Size([4, 37, 2])\n",
            "torch.Size([59, 102, 2])\n",
            "torch.Size([35, 169, 2])\n",
            "torch.Size([48, 155, 2])\n",
            "torch.Size([18, 191, 2])\n",
            "torch.Size([1, 242, 2])\n",
            "torch.Size([3, 35, 2])\n",
            "torch.Size([14, 184, 2])\n",
            "torch.Size([1, 234, 2])\n",
            "torch.Size([57, 116, 2])\n",
            "torch.Size([25, 46, 2])\n",
            "torch.Size([4, 212, 2])\n",
            "torch.Size([93, 85, 2])\n",
            "torch.Size([63, 104, 2])\n",
            "torch.Size([77, 98, 2])\n",
            "torch.Size([35, 163, 2])\n",
            "torch.Size([10, 192, 2])\n",
            "torch.Size([26, 51, 2])\n",
            "torch.Size([53, 99, 2])\n",
            "torch.Size([1, 247, 2])\n",
            "torch.Size([9, 198, 2])\n",
            "torch.Size([81, 82, 2])\n",
            "torch.Size([1, 229, 2])\n",
            "torch.Size([75, 66, 2])\n",
            "torch.Size([78, 71, 2])\n",
            "torch.Size([52, 93, 2])\n",
            "torch.Size([30, 175, 2])\n",
            "torch.Size([96, 81, 2])\n",
            "torch.Size([78, 132, 2])\n",
            "torch.Size([35, 164, 2])\n",
            "torch.Size([80, 72, 2])\n",
            "torch.Size([51, 77, 2])\n",
            "torch.Size([2, 31, 2])\n",
            "torch.Size([1, 225, 2])\n",
            "torch.Size([12, 200, 2])\n",
            "torch.Size([36, 161, 2])\n",
            "torch.Size([63, 104, 2])\n",
            "torch.Size([53, 60, 2])\n",
            "torch.Size([4, 215, 2])\n",
            "torch.Size([45, 65, 2])\n",
            "torch.Size([1, 241, 2])\n",
            "torch.Size([89, 114, 2])\n",
            "torch.Size([4, 208, 2])\n",
            "torch.Size([20, 174, 2])\n",
            "torch.Size([16, 190, 2])\n",
            "torch.Size([63, 107, 2])\n",
            "torch.Size([60, 86, 2])\n",
            "torch.Size([30, 53, 2])\n",
            "torch.Size([41, 159, 2])\n",
            "torch.Size([12, 189, 2])\n",
            "torch.Size([92, 126, 2])\n",
            "torch.Size([12, 181, 2])\n",
            "torch.Size([1, 226, 2])\n",
            "torch.Size([96, 89, 2])\n",
            "torch.Size([55, 112, 2])\n",
            "torch.Size([78, 140, 2])\n",
            "torch.Size([53, 151, 2])\n",
            "torch.Size([2, 27, 2])\n",
            "torch.Size([1, 230, 2])\n",
            "torch.Size([42, 61, 2])\n",
            "torch.Size([1, 236, 2])\n",
            "torch.Size([57, 116, 2])\n",
            "torch.Size([55, 90, 2])\n",
            "torch.Size([67, 137, 2])\n",
            "torch.Size([68, 62, 2])\n",
            "torch.Size([62, 107, 2])\n",
            "torch.Size([54, 91, 2])\n",
            "torch.Size([60, 86, 2])\n",
            "torch.Size([54, 96, 2])\n",
            "torch.Size([17, 186, 2])\n",
            "torch.Size([66, 70, 2])\n",
            "torch.Size([2, 223, 2])\n",
            "torch.Size([4, 217, 2])\n",
            "torch.Size([58, 100, 2])\n",
            "torch.Size([8, 194, 2])\n",
            "torch.Size([86, 128, 2])\n",
            "torch.Size([36, 158, 2])\n",
            "torch.Size([90, 80, 2])\n",
            "torch.Size([63, 147, 2])\n",
            "torch.Size([66, 142, 2])\n",
            "torch.Size([53, 118, 2])\n",
            "torch.Size([59, 106, 2])\n",
            "torch.Size([50, 117, 2])\n",
            "torch.Size([1, 30, 2])\n",
            "torch.Size([2, 239, 2])\n",
            "torch.Size([23, 178, 2])\n",
            "torch.Size([52, 105, 2])\n",
            "torch.Size([53, 111, 2])\n",
            "torch.Size([73, 73, 2])\n",
            "torch.Size([82, 129, 2])\n",
            "torch.Size([4, 206, 2])\n",
            "torch.Size([45, 56, 2])\n",
            "torch.Size([19, 42, 2])\n",
            "torch.Size([3, 227, 2])\n",
            "torch.Size([8, 196, 2])\n",
            "torch.Size([5, 209, 2])\n",
            "torch.Size([58, 152, 2])\n",
            "torch.Size([27, 173, 2])\n",
            "torch.Size([3, 219, 2])\n",
            "torch.Size([92, 134, 2])\n",
            "torch.Size([58, 101, 2])\n",
            "torch.Size([33, 170, 2])\n",
            "torch.Size([54, 91, 2])\n",
            "torch.Size([7, 34, 2])\n",
            "torch.Size([55, 154, 2])\n",
            "torch.Size([97, 79, 2])\n",
            "torch.Size([52, 78, 2])\n",
            "torch.Size([64, 145, 2])\n",
            "torch.Size([51, 121, 2])\n",
            "torch.Size([21, 179, 2])\n",
            "torch.Size([21, 47, 2])\n",
            "torch.Size([84, 131, 2])\n",
            "torch.Size([56, 112, 2])\n",
            "torch.Size([59, 102, 2])\n",
            "torch.Size([90, 127, 2])\n",
            "torch.Size([1, 228, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBA6e5XpWKvI",
        "colab_type": "text"
      },
      "source": [
        "## Building a DeepSet model\n",
        "\n",
        "you only have three components - a fully connected network that creates the node embedding, a sum operation, and a classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo905dI-WKvI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64d07e01-30e3-4231-9b1a-b2020241ea3c"
      },
      "source": [
        "# the linear layer operates on the last dimension:\n",
        "\n",
        "linear_layer = nn.Linear(10,5)\n",
        "\n",
        "linear_layer(  torch.rand((345,10)) ).shape, linear_layer(  torch.rand((345,76,10)) ).shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([345, 5]), torch.Size([345, 76, 5]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2OrLUQHWKv8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "54900760-8cba-4837-cee8-01797a680170"
      },
      "source": [
        "# for the the mean operation you need to specify the dimension:\n",
        "\n",
        "x = torch.rand((42,15,10))\n",
        "\n",
        "torch.mean(x,dim=1).shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([42, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8euezaiGrJse",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ad8f3f6-2a19-4228-eaaa-782041169d04"
      },
      "source": [
        "cov = nn.Conv1d(26, 3, 2) \n",
        "cov(  torch.rand((1,26,2)) ).shape\n",
        "\n",
        "        # self.conv_1 = nn.Conv1d(input_dim, 64, 1)\n",
        "        # self.conv_2 = nn.Conv1d(64, 128, 1)\n",
        "        # self.conv_3 = nn.Conv1d(128, 1024, 1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VIHAqKcWKwK",
        "colab_type": "text"
      },
      "source": [
        "## build the model, train, submit when you reach above 75% accuracy on the validation set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PMzO8ybBUUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class DeepSet(nn.Module):\n",
        "#     def __init__(self, in_dim, n_classes):\n",
        "#         super(DeepSet, self).__init__()\n",
        "#         self.layer1 = nn.Linear(in_dim, 512)\n",
        "#         self.layer2 = nn.Linear(512,512)\n",
        "#         self.layer3 = nn.Linear(512,512)\n",
        "#         # self.layer4 = nn.Linear(512,264)\n",
        "#         self.classify = nn.Linear(512, n_classes)\n",
        "\n",
        "#         self.droput = nn.Dropout(0.2)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         out = F.relu(self.layer1(x))\n",
        "#         # add dropout layer\n",
        "#         out = self.droput(out)\n",
        "#         out = F.relu(self.layer2(out))\n",
        "#         out = F.relu(self.layer3(out))\n",
        "#         out = self.droput(out)\n",
        "#         # out = F.relu(self.layer4(out))\n",
        "#         # mean operation\n",
        "#         out = torch.mean(out,dim=1)\n",
        "#         return F.log_softmax(self.classify(out), dim=1)\n",
        "\n",
        "       "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VHAfB_6PKOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " class DeepSet(nn.Module):\n",
        "    def __init__(self, in_dim, n_classes):\n",
        "        super(DeepSet, self).__init__()\n",
        "        # self.conv_1 = nn.Conv1d(input_dim, 64, 1) \n",
        "        self.fc_1 = nn.Linear(in_dim, 712)\n",
        "        self.fc_2 = nn.Linear(712, 512)\n",
        "        self.fc_3 = nn.Linear(512, 512)\n",
        "        self.fc_4 = nn.Linear(512, 256)\n",
        "        self.classify = nn.Linear(256, n_classes)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc_1(x))\n",
        "        x = F.relu(self.fc_2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc_3(x))\n",
        "        x = F.relu(self.fc_4(x))\n",
        "        x = self.dropout(x)\n",
        "        # mean operation\n",
        "        x = torch.mean(x,dim=1)\n",
        "        return F.log_softmax(self.classify(x), dim=1)\n",
        "        "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1_CZPx_WKwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k = len(np.unique(ds.label))\n",
        "net = DeepSet(2, k)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8jc0nTwWKxU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUKOlUn5WKxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_accuracy(data_loader,net,criterion):\n",
        "    \n",
        "    net.eval()\n",
        "    \n",
        "    \n",
        "    total_number = 0\n",
        "    total_correct = 0\n",
        "    \n",
        "    for x,y in data_loader:\n",
        "        \n",
        "        prediction = net(x.cuda()).cpu().data.numpy()\n",
        "        loss = criterion(prediction,torch.LongTensor(y).cuda()) # torch.LongTensor(targets) convert the (10000,) to (10000,1)\n",
        "        print(loss)\n",
        "        prediction = np.argmax(prediction,axis=1)\n",
        "        \n",
        "        correct = len( np.where(prediction==y.data.numpy())[0] )\n",
        "        \n",
        "        total_correct+=correct\n",
        "        total_number+=x.shape[0]\n",
        "        \n",
        "    return total_correct/float(total_number), loss.item()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTfnlrhEWKx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_ds = CustomDataset('/content/drive/My Drive/ML course/valid_ds.h5')\n",
        "batch_size = 50\n",
        "batch_sampler_test_ds = CustomBatchSampler(test_ds.n_points, batch_size)\n",
        "data_loader_test = DataLoader(test_ds, batch_sampler=batch_sampler_test_ds)\n",
        "\n",
        "# compute_accuracy(data_loader_test,net)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4dolkGKWKyD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5cdd858b34fc40fe955a632fbcf43535",
            "d6e46a801dfa49cf8e7178764f3bcf83",
            "f45711a4a81c481f94b5db3f6dfa873a",
            "c0408685a1b04d1e96bb3a9cf91fded3",
            "5819c44336274f74ac0b758fd130ee36",
            "6cd18403219f4aa6a3795de471f23673",
            "1999926355704a5790a5c4fef1b105ed",
            "9805561b86f942ab92273dfd172107b1"
          ]
        },
        "outputId": "3adb96a6-e173-4962-b151-7671b66ae4d5"
      },
      "source": [
        "import  torch\n",
        "from torch.utils import data\n",
        "from tqdm.notebook import tqdm\n",
        "# Stochastic gradient descent optimaizer with learning rate of 0.01\n",
        "# import torch.optim as optim\n",
        "from torch.optim import Adam, SGD\n",
        "# optimizer = Adam(net.parameters(), lr=0.01)\n",
        "optimizer = SGD(net.parameters(), lr=0.01) \n",
        "# Loss function \n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "# CUDA for PyTorch\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "torch.backends.cudnn.benchmark = True\n",
        "if torch.cuda.is_available():\n",
        "    net.cuda()\n",
        "# number of epoches to train the model \n",
        "n_epochs = 70\n",
        "# Initialsize tracker for minimum validation loss \n",
        "valid_loss_min = np.Inf\n",
        "\n",
        "loss_vs_epoch = []\n",
        "accuracy_vs_epoch = []\n",
        "\n",
        "# Loop over the epochs: \n",
        "for epoch in tqdm( range(n_epochs) ):\n",
        "    ##  Training ## \n",
        "    net.train() # prep model for training \n",
        "    for x,y in data_loader:\n",
        "      data, target = x.to(device), torch.LongTensor(y).to(device)\n",
        "      # Clear the gradients for all optimized variables \n",
        "      optimizer.zero_grad()\n",
        "      # Farward pass: compute predicted outputs ny passing inputs to the model \n",
        "      pred = net(data)\n",
        "      # Loss calculation \n",
        "      loss = loss_func(pred,target) # torch.LongTensor(targets) convert the (10000,) to (10000,1)\n",
        "      # Backward pass: compute gradient of the loss with respect to model parameters\n",
        "      loss.backward()\n",
        "      # Model weight modification based on the optimizer \n",
        "      optimizer.step()\n",
        "    ## Validation ##       \n",
        "    net.eval() # evaluation mode - use the function above for each epoch \n",
        "    for x,y in data_loader_test:\n",
        "      data, target = x.to(device), torch.LongTensor(y).to(device)\n",
        "      # Farward pass: compute predicted outputs ny passing inputs to the model \n",
        "      pred = net(data)\n",
        "      # Loss calculation \n",
        "      loss = loss_func(pred,target) # torch.LongTensor(target) convert the (n,) to n,1)\n",
        "    \n",
        "    training_accuracy, training_loss = compute_accuracy(data_loader,net, loss_func)\n",
        "    validation_accuracy, validation_loss = compute_accuracy(data_loader_test,net, loss_func)\n",
        "    \n",
        "    print(validation_accuracy)\n",
        "\n",
        "    loss_vs_epoch.append([training_loss, validation_loss])\n",
        "    \n",
        "    accuracy_vs_epoch.append([training_accuracy, validation_accuracy])\n",
        "\n",
        "    # Save model of Validation loss has decreased\n",
        "    if validation_loss <= valid_loss_min:\n",
        "      print('Validation loss decreased ({:.6f} --> {:.6f}). Saving model ...'.format(valid_loss_min, validation_loss))\n",
        "      torch.save(net.state_dict(), 'model_rotation.pt')\n",
        "      valid_loss_min = validation_loss\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5cdd858b34fc40fe955a632fbcf43535",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=70.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0.098\n",
            "0.098\n",
            "0.098\n",
            "0.098\n",
            "0.098\n",
            "0.098\n",
            "0.098\n",
            "0.098\n",
            "0.098\n",
            "0.098\n",
            "0.098\n",
            "0.1346\n",
            "0.098\n",
            "0.098\n",
            "0.098\n",
            "0.1464\n",
            "0.098\n",
            "0.1509\n",
            "0.1839\n",
            "0.1965\n",
            "0.1995\n",
            "0.2176\n",
            "0.1748\n",
            "0.2326\n",
            "0.2532\n",
            "0.247\n",
            "0.2684\n",
            "0.2575\n",
            "0.2903\n",
            "0.2688\n",
            "0.2597\n",
            "0.2534\n",
            "0.2692\n",
            "0.2322\n",
            "0.3064\n",
            "0.3174\n",
            "0.3156\n",
            "0.2945\n",
            "0.2819\n",
            "0.1849\n",
            "0.3353\n",
            "0.3689\n",
            "0.3214\n",
            "0.3483\n",
            "0.3866\n",
            "0.3827\n",
            "0.4041\n",
            "0.4127\n",
            "0.4014\n",
            "0.4863\n",
            "0.5068\n",
            "0.429\n",
            "0.4537\n",
            "0.3601\n",
            "0.5658\n",
            "0.6033\n",
            "0.5956\n",
            "0.6191\n",
            "0.6483\n",
            "0.63\n",
            "0.6658\n",
            "0.6928\n",
            "0.7117\n",
            "0.6459\n",
            "0.7073\n",
            "0.7299\n",
            "0.7429\n",
            "0.674\n",
            "0.7601\n",
            "0.7782\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZwV9luTWKyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": []
    }
  ]
}